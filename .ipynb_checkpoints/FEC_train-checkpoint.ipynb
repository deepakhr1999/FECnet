{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.google/tools/datasets/google-facial-expression/\n",
    "import imageio\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import hashlib\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "import pickle\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('FEC_dataset/two_class_ready.csv')\n",
    "train_df.head()\n",
    "# hyperparams\n",
    "SHAPE=(160,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136379 triplets in the dataset\n",
      "Before loop\n",
      "====================================\n",
      "1th element:  (128, 160, 160, 3)\n",
      "2th element:  (128, 160, 160, 3)\n",
      "3th element:  (128, 160, 160, 3)\n",
      "dummy (128,)\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "1th element:  (128, 160, 160, 3)\n",
      "2th element:  (128, 160, 160, 3)\n",
      "3th element:  (128, 160, 160, 3)\n",
      "dummy (128,)\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "1th element:  (128, 160, 160, 3)\n",
      "2th element:  (128, 160, 160, 3)\n",
      "3th element:  (128, 160, 160, 3)\n",
      "dummy (128,)\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "1th element:  (128, 160, 160, 3)\n",
      "2th element:  (128, 160, 160, 3)\n",
      "3th element:  (128, 160, 160, 3)\n",
      "dummy (128,)\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "1th element:  (128, 160, 160, 3)\n",
      "2th element:  (128, 160, 160, 3)\n",
      "3th element:  (128, 160, 160, 3)\n",
      "dummy (128,)\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n"
     ]
    }
   ],
   "source": [
    "def TripletGen(data, root='FEC_dataset/formatted', batch_size=128, rescale=1./255, shape=SHAPE[:2]):\n",
    "    # yielding format must be [anchorlist, positlist, negatlist], dummy\n",
    "    # 3 elements of shape (@batch_size,*@shape) in the list and an empty np.array of shape(@batch_size,1)\n",
    "    \n",
    "    ## the init code\n",
    "    n = len(data)\n",
    "    iterations = math.ceil(n/batch_size)\n",
    "    print(f\"Found {n} triplets in the dataset\")\n",
    "    \n",
    "    def genFunc(batch_size = batch_size):\n",
    "        y_dummy = np.empty((batch_size,))\n",
    "        while True:\n",
    "            for i in range(iterations):\n",
    "                # use start and end as indices to work with\n",
    "                start, end = i*batch_size, min((i+1)*batch_size, n)\n",
    "                batch_size_eff = end - start\n",
    "\n",
    "                arr_shape = (batch_size_eff, *shape, 3)\n",
    "                anchor = np.empty(arr_shape)\n",
    "                positive = np.empty(arr_shape)\n",
    "                negative = np.empty(arr_shape)\n",
    "\n",
    "                for arr_index in range(batch_size_eff):\n",
    "                    data_index = arr_index + start\n",
    "\n",
    "                    # anchor\n",
    "                    path = os.path.join(root, data[\"Image1\"][data_index])\n",
    "                    temp = image.load_img( path, target_size = shape )\n",
    "                    anchor[arr_index] = image.img_to_array(temp)*rescale\n",
    "\n",
    "                    # positive\n",
    "                    path = os.path.join(root, data[\"Image2\"][data_index])\n",
    "                    temp = image.load_img( path, target_size = shape )\n",
    "                    positive[arr_index] = image.img_to_array(temp)*rescale\n",
    "\n",
    "                    # negative\n",
    "                    path = os.path.join(root, data[\"Image3\"][data_index])\n",
    "                    temp = image.load_img( path, target_size = shape )\n",
    "                    negative[arr_index] = image.img_to_array(temp)*rescale\n",
    "\n",
    "                yield [anchor, positive, negative], y_dummy[:batch_size_eff]\n",
    "    return genFunc(), iterations\n",
    "\n",
    "imgs, iterations = TripletGen(train_df)\n",
    "print(\"Before loop\")\n",
    "print(\"==\"*18)\n",
    "\n",
    "for i in range(5):\n",
    "    left, right = next(imgs)\n",
    "    for i, thing in enumerate(left):\n",
    "        print(f\"{i+1}th element: \",thing.shape)\n",
    "    print(\"dummy\", right.shape)\n",
    "    print(\"=-\"*18)\n",
    "    \n",
    "del(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tf_triplet_loss(y_true, y_pred, alpha=0.4):\n",
    "    n = y_pred.shape.as_list()[-1]\n",
    "    anchor = y_pred[:,0:n//3]\n",
    "    positive = y_pred[:,n//3:2*n//3]\n",
    "    negative = y_pred[:,2*n//3:n]\n",
    "    \n",
    "    sigma_pd = tf.math.reduce_sum(tf.norm(positive-anchor, axis=1))\n",
    "    sigma_nd = tf.math.reduce_sum(tf.norm(negative-anchor, axis=1) + alpha)\n",
    "\n",
    "    loss = sigma_nd - sigma_pd\n",
    "    return tf.math.log(1.0+tf.math.exp(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0821 20:45:22.903306 139735916132160 deprecation.py:506] From /home/deepak/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "anchor_input (InputLayer)       [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "positive_input (InputLayer)     [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "negative_input (InputLayer)     [(None, 160, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 16)           704688      anchor_input[0][0]               \n",
      "                                                                 positive_input[0][0]             \n",
      "                                                                 negative_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "merged_layer (Concatenate)      (None, 48)           0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "                                                                 sequential[3][0]                 \n",
      "==================================================================================================\n",
      "Total params: 704,688\n",
      "Trainable params: 704,688\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l2 = tf.keras.regularizers.l2\n",
    "alpha = 0\n",
    "base_model = Sequential([\n",
    "    #first convolution\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=SHAPE),#, activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #second\n",
    "    Conv2D(32, (3,3), activation='relu'),#, activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #third\n",
    "    Conv2D(64, (3,3), activation='relu'),#, activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #fourth\n",
    "    Conv2D(64, (3,3), activation='relu'),#, activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #fifth\n",
    "    Conv2D(64, (3,3), activation='relu'),#, activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    # hidden\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='softplus'),#, activity_regularizer=l2(alpha)),\n",
    "    #Last layer\n",
    "    Dense(16, activation='tanh')\n",
    "])\n",
    "anchor_input = Input(SHAPE, name='anchor_input')\n",
    "positive_input = Input(SHAPE, name='positive_input')\n",
    "negative_input = Input(SHAPE, name='negative_input')\n",
    "\n",
    "encoded_anchor = base_model(anchor_input)\n",
    "encoded_positive = base_model(positive_input)\n",
    "encoded_negative = base_model(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "train_model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 136379 triplets in the dataset\n"
     ]
    }
   ],
   "source": [
    "train_model.compile(loss=batch_tf_triplet_loss, optimizer=Adam(learning_rate=0.0001))\n",
    "train, steps = TripletGen(train_df, batch_size=64)\n",
    "checkpoint = ModelCheckpoint(\"emotion.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get a taste of the model\n",
    "# 1.0238742\n",
    "# m, b = 120, 120\n",
    "# dgen, dsteps = TripletGen(train_df[:m], batch_size=b)\n",
    "# x = []\n",
    "# for i, (images, dy) in tqdm(enumerate(dgen)):\n",
    "#     if i< math.ceil(m//b):\n",
    "#         x.append(train_model.predict(images))\n",
    "#     else: \n",
    "#         break\n",
    "# print(len(x))\n",
    "# loss = tf.Variable(tf.zeros([1]))\n",
    "# for i, num in enumerate(x):\n",
    "#     loss = loss + batch_tf_triplet_loss(None, tf.convert_to_tensor(num, np.float32))\n",
    "# print(\"before sess\")\n",
    "# with tf.Session() as sess:\n",
    "#     init_op = tf.global_variables_initializer()\n",
    "#     sess.run(init_op)\n",
    "#     with sess.as_default():\n",
    "#         print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  27/1066 [..............................] - ETA: 54:27 - loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_model.fit_generator(train, epochs=10, steps_per_epoch=steps, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "seq = train_model.layers[3]\n",
    "seq.layers[6]#.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[anchor_input], outputs=encoded_anchor)\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded weights from h5 file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, steps = TripletGen(train_df[:1], batch_size=1)\n",
    "images, _ = next(train)\n",
    "anchor, positive, negative = tuple(images)\n",
    "print(anchor.shape)\n",
    "# a,p,n = train_model.predict(anchor), model.predict(positive), model.predict(negative)\n",
    "train_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
