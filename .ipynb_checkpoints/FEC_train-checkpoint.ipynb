{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ai.google/tools/datasets/google-facial-expression/\n",
    "import imageio\n",
    "import os\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import hashlib\n",
    "from skimage.transform import resize\n",
    "import math\n",
    "import pickle\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import * \n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('FEC_dataset/two_class_ready.csv')\n",
    "train_df.head()\n",
    "# hyperparams\n",
    "SHAPE=(160,160,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TripletGen(data, root='FEC_dataset/formatted', batch_size=128, rescale=1./255, shape=SHAPE[:2]):\n",
    "    # yielding format must be [anchorlist, positlist, negatlist], dummy\n",
    "    # 3 elements of shape (@batch_size,*@shape) in the list and an empty np.array of shape(@batch_size,1)\n",
    "    \n",
    "    ## the init code\n",
    "    n = len(data)\n",
    "    iterations = math.ceil(n/batch_size)\n",
    "    print(f\"Found {n} triplets in the dataset\")\n",
    "    \n",
    "    def genFunc(batch_size = batch_size):\n",
    "        y_dummy = np.empty((batch_size,))\n",
    "        while True:\n",
    "            for i in range(iterations):\n",
    "                # use start and end as indices to work with\n",
    "                start, end = i*batch_size, min((i+1)*batch_size, n)\n",
    "                batch_size_eff = end - start\n",
    "\n",
    "                arr_shape = (batch_size_eff, *shape, 3)\n",
    "                anchor = np.empty(arr_shape)\n",
    "                positive = np.empty(arr_shape)\n",
    "                negative = np.empty(arr_shape)\n",
    "\n",
    "                for arr_index in range(batch_size_eff):\n",
    "                    data_index = arr_index + start\n",
    "\n",
    "                    # anchor\n",
    "                    path = os.path.join(root, data[\"Image1\"][data_index])\n",
    "                    temp = image.load_img( path, target_size = shape )\n",
    "                    anchor[arr_index] = image.img_to_array(temp)*rescale\n",
    "\n",
    "                    # positive\n",
    "                    path = os.path.join(root, data[\"Image2\"][data_index])\n",
    "                    temp = image.load_img( path, target_size = shape )\n",
    "                    positive[arr_index] = image.img_to_array(temp)*rescale\n",
    "\n",
    "                    # negative\n",
    "                    path = os.path.join(root, data[\"Image3\"][data_index])\n",
    "                    temp = image.load_img( path, target_size = shape )\n",
    "                    negative[arr_index] = image.img_to_array(temp)*rescale\n",
    "\n",
    "                yield [anchor, positive, negative], y_dummy[:batch_size_eff]\n",
    "    return genFunc(), iterations\n",
    "\n",
    "imgs, iterations = TripletGen(train_df)\n",
    "print(\"Before loop\")\n",
    "print(\"==\"*18)\n",
    "\n",
    "for i in range(5):\n",
    "    left, right = next(imgs)\n",
    "    for i, thing in enumerate(left):\n",
    "        print(f\"{i+1}th element: \",thing.shape)\n",
    "    print(\"dummy\", right.shape)\n",
    "    print(\"=-\"*18)\n",
    "    \n",
    "del(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tf_triplet_loss(y_true, y_pred, alpha=0.4):\n",
    "    n = y_pred.shape.as_list()[-1]\n",
    "    anchor = y_pred[:,0:n//3]\n",
    "    positive = y_pred[:,n//3:2*n//3]\n",
    "    negative = y_pred[:,2*n//3:n]\n",
    "    \n",
    "    sigma_pd = tf.math.reduce_sum(tf.norm(positive-anchor, axis=1))\n",
    "    sigma_nd = tf.math.reduce_sum(tf.norm(negative-anchor, axis=1) + alpha)\n",
    "\n",
    "    loss = sigma_nd - sigma_pd\n",
    "    return tf.math.log(1.0+tf.math.exp(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = tf.keras.regularizers.l2\n",
    "alpha = 0.01\n",
    "base_model = Sequential([\n",
    "    #first convolution\n",
    "    Conv2D(16, (3,3), activation='relu', input_shape=SHAPE, activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #second\n",
    "    Conv2D(32, (3,3), activation='relu', activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #third\n",
    "    Conv2D(64, (3,3), activation='relu', activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #fourth\n",
    "    Conv2D(64, (3,3), activation='relu', activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    #fifth\n",
    "    Conv2D(64, (3,3), activation='relu', activity_regularizer=l2(alpha)),\n",
    "    MaxPool2D(2,2),\n",
    "    # hidden\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='softplus', activity_regularizer=l2(alpha)),\n",
    "    #Last layer\n",
    "    Dense(16, activation='tanh')\n",
    "])\n",
    "anchor_input = Input(SHAPE, name='anchor_input')\n",
    "positive_input = Input(SHAPE, name='positive_input')\n",
    "negative_input = Input(SHAPE, name='negative_input')\n",
    "\n",
    "encoded_anchor = base_model(anchor_input)\n",
    "encoded_positive = base_model(positive_input)\n",
    "encoded_negative = base_model(negative_input)\n",
    "\n",
    "\n",
    "merged_vector = concatenate([encoded_anchor, encoded_positive, encoded_negative], axis=-1, name='merged_layer')\n",
    "\n",
    "train_model = Model(inputs=[anchor_input,positive_input, negative_input], outputs=merged_vector)\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.compile(loss=batch_tf_triplet_loss, optimizer=Adam())\n",
    "train, steps = TripletGen(train_df, batch_size=128)\n",
    "checkpoint = ModelCheckpoint(\"emotion.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get a taste of the model\n",
    "# 1.0238742\n",
    "m, b = 120, 120\n",
    "dgen, dsteps = TripletGen(train_df[:m], batch_size=b)\n",
    "x = []\n",
    "for i, (images, dy) in tqdm(enumerate(dgen)):\n",
    "    if i< math.ceil(m//b):\n",
    "        x.append(train_model.predict(images))\n",
    "    else: \n",
    "        break\n",
    "print(len(x))\n",
    "loss = tf.Variable(tf.zeros([1]))\n",
    "for i, num in enumerate(x):\n",
    "    loss = loss + batch_tf_triplet_loss(None, tf.convert_to_tensor(num, np.float32))\n",
    "print(\"before sess\")\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    with sess.as_default():\n",
    "        print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = train_model.fit_generator(train, epochs=10, steps_per_epoch=steps, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model.save_weights(\"model.h5\")\n",
    "# print(\"Saved model to disk\")\n",
    "seq = train_model.layers[3]\n",
    "seq.layers[6]#.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[anchor_input], outputs=encoded_anchor)\n",
    "model.load_weights(\"model.h5\")\n",
    "print(\"Loaded weights from h5 file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, steps = TripletGen(train_df[:1], batch_size=1)\n",
    "images, _ = next(train)\n",
    "anchor, positive, negative = tuple(images)\n",
    "print(anchor.shape)\n",
    "# a,p,n = train_model.predict(anchor), model.predict(positive), model.predict(negative)\n",
    "train_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
